{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2025-06-05T23:04:52.219611Z",
     "end_time": "2025-06-05T23:04:56.120455Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import RobustScaler # 使用 RobustScaler 更好地处理异常值\n",
    "from sklearn.model_selection import TimeSeriesSplit # 保持时序交叉验证\n",
    "import warnings\n",
    "import gc # 导入垃圾回收模块\n",
    "import os # 用于文件操作\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# 设置随机种子\n",
    "def set_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    # 确保在 CUDA 可用时设置 CUDA 相关的种子\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-06-05T23:05:33.118913Z",
     "end_time": "2025-06-05T23:05:33.142583Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "\n",
    "class StockDataProcessor:\n",
    "    def __init__(self, window_size=20):\n",
    "        self.window_size = window_size\n",
    "\n",
    "    def _calculate_single_stock_features(self, df_single_stock):\n",
    "        \"\"\"为单个股票的DataFrame计算特征（假设已按日期排序）\"\"\"\n",
    "        features = pd.DataFrame(index=df_single_stock.index)\n",
    "\n",
    "        # 基础价格特征\n",
    "        features['returns'] = df_single_stock['收盘'].pct_change()\n",
    "        features['log_returns'] = np.log(df_single_stock['收盘'] / df_single_stock['收盘'].shift(1))\n",
    "\n",
    "        # 价格相关特征\n",
    "        features['high_low_ratio'] = df_single_stock['最高'] / df_single_stock['最低'].replace(0, np.nan)\n",
    "        features['close_open_ratio'] = df_single_stock['收盘'] / df_single_stock['开盘'].replace(0, np.nan)\n",
    "\n",
    "        # 成交量比率\n",
    "        volume_ma = df_single_stock['成交量'].rolling(window=20, min_periods=1).mean()\n",
    "        features['volume_ratio'] = df_single_stock['成交量'] / volume_ma.replace(0, np.nan)\n",
    "\n",
    "        # RSI\n",
    "        delta = df_single_stock['收盘'].diff()\n",
    "        gain = (delta.where(delta > 0, 0)).rolling(window=14, min_periods=1).mean()\n",
    "        loss = (-delta.where(delta < 0, 0)).rolling(window=14, min_periods=1).mean()\n",
    "        rs = gain / loss.replace(0, np.nan)\n",
    "        features['rsi'] = 100 - (100 / (1 + rs))\n",
    "\n",
    "        # 移动平均\n",
    "        for period in [5, 10, 20, 60]:\n",
    "            ma = df_single_stock['收盘'].rolling(window=period, min_periods=1).mean()\n",
    "            features[f'ma_{period}'] = ma\n",
    "            features[f'ma_ratio_{period}'] = df_single_stock['收盘'] / ma.replace(0, np.nan)\n",
    "\n",
    "        # 布林带\n",
    "        ma20 = df_single_stock['收盘'].rolling(window=20, min_periods=1).mean()\n",
    "        std20 = df_single_stock['收盘'].rolling(window=20, min_periods=1).std()\n",
    "        features['bb_upper'] = ma20 + 2 * std20\n",
    "        features['bb_lower'] = ma20 - 2 * std20\n",
    "        bb_diff = features['bb_upper'] - features['bb_lower']\n",
    "        features['bb_width'] = bb_diff / ma20.replace(0, np.nan)\n",
    "        features['bb_position'] = ((df_single_stock['收盘'] - features['bb_lower']) /\n",
    "                                   bb_diff.replace(0, np.nan))\n",
    "\n",
    "        # MACD\n",
    "        exp1 = df_single_stock['收盘'].ewm(span=12, adjust=False, min_periods=1).mean()\n",
    "        exp2 = df_single_stock['收盘'].ewm(span=26, adjust=False, min_periods=1).mean()\n",
    "        features['macd'] = exp1 - exp2\n",
    "        features['macd_signal'] = features['macd'].ewm(span=9, adjust=False, min_periods=1).mean()\n",
    "        features['macd_diff'] = features['macd'] - features['macd_signal']\n",
    "\n",
    "        # OBV\n",
    "        features['obv'] = (np.sign(df_single_stock['收盘'].diff().fillna(0)) * df_single_stock['成交量']).fillna(0).cumsum()\n",
    "        features['volume_ma'] = df_single_stock['成交量'].rolling(window=20, min_periods=1).mean()\n",
    "\n",
    "        # 波动率\n",
    "        features['volatility'] = df_single_stock['收盘'].pct_change().rolling(window=20, min_periods=1).std()\n",
    "\n",
    "        # 价格位置\n",
    "        price_min = df_single_stock['最低'].rolling(window=20, min_periods=1).min()\n",
    "        price_max = df_single_stock['最高'].rolling(window=20, min_periods=1).max()\n",
    "        price_range = price_max - price_min\n",
    "        features['price_position'] = ((df_single_stock['收盘'] - price_min) /\n",
    "                                      price_range.replace(0, np.nan))\n",
    "\n",
    "        # 新增特征: Stochastic Oscillator (%K and %D)\n",
    "        low_14 = df_single_stock['最低'].rolling(window=14, min_periods=1).min()\n",
    "        high_14 = df_single_stock['最高'].rolling(window=14, min_periods=1).max()\n",
    "        stoch_k_numerator = df_single_stock['收盘'] - low_14\n",
    "        stoch_k_denominator = (high_14 - low_14).replace(0, np.nan)\n",
    "        features['stoch_k'] = 100 * (stoch_k_numerator / stoch_k_denominator)\n",
    "        features['stoch_d'] = features['stoch_k'].rolling(window=3, min_periods=1).mean()\n",
    "\n",
    "        # 新增特征: Rate of Change (ROC)\n",
    "        for period in [10, 20]:\n",
    "             features[f'roc_{period}'] = df_single_stock['收盘'].pct_change(periods=period) * 100\n",
    "\n",
    "        features = features.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "        return features"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-06-05T23:05:34.486668Z",
     "end_time": "2025-06-05T23:05:34.489388Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    " def calculate_all_features(self, df_all_stocks):\n",
    "        \"\"\"对所有股票应用特征计算（按股票分组并排序）\"\"\"\n",
    "        original_index = df_all_stocks.index\n",
    "        df_all_stocks_sorted = df_all_stocks.sort_values(['股票代码', '日期'])\n",
    "\n",
    "        all_features_list = []\n",
    "        for stock_code, group_df in df_all_stocks_sorted.groupby('股票代码'):\n",
    "            single_stock_features = self._calculate_single_stock_features(group_df.copy())\n",
    "            all_features_list.append(single_stock_features)\n",
    "\n",
    "        if not all_features_list:\n",
    "            if not df_all_stocks.empty:\n",
    "                sample_cols_df = self._calculate_single_stock_features(df_all_stocks.iloc[:1].copy())\n",
    "                return pd.DataFrame(columns=sample_cols_df.columns, index=original_index)\n",
    "            return pd.DataFrame(index=original_index)\n",
    "\n",
    "        final_features_df = pd.concat(all_features_list)\n",
    "        final_features_df = final_features_df.reindex(original_index)\n",
    "        return final_features_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-06-05T23:05:36.366821Z",
     "end_time": "2025-06-05T23:05:36.374015Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "   def prepare_sequences(self, stock_data, features_df, max_sequences=None):\n",
    "        \"\"\"准备序列数据用于LSTM，确保特征与目标正确对齐，并支持内存限制\"\"\"\n",
    "        X, y, dates, stocks = [], [], [], []\n",
    "\n",
    "        # 预估特征数量，用于初始化空 NumPy 数组\n",
    "        num_expected_features = features_df.shape[1] if features_df is not None and not features_df.empty else 0\n",
    "        if num_expected_features == 0 and not stock_data.empty:\n",
    "            print(\"警告: 计算的特征数量为0。请检查特征计算逻辑。\")\n",
    "            # 如果没有特征，则无法构建序列，直接返回空数组\n",
    "            return np.array([]).reshape(0, self.window_size, 0), np.array([]), [], []\n",
    "\n",
    "        sequence_count = 0 # 跟踪已生成的序列数量\n",
    "\n",
    "        for stock_code in stock_data['股票代码'].unique():\n",
    "            current_stock_data_slice = stock_data[stock_data['股票代码'] == stock_code]\n",
    "            current_stock_features_slice = features_df.loc[current_stock_data_slice.index]\n",
    "\n",
    "            temp_df = current_stock_data_slice[['日期', '收盘']].join(current_stock_features_slice)\n",
    "            temp_df = temp_df.sort_values('日期').reset_index(drop=True)\n",
    "\n",
    "            temp_df['future_return'] = temp_df['收盘'].shift(-1) / temp_df['收盘'] - 1\n",
    "            temp_df['future_return'] = temp_df['future_return'].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "            feature_column_names = current_stock_features_slice.columns.tolist()\n",
    "\n",
    "            for i in range(self.window_size - 1, len(temp_df) - 1):\n",
    "                if max_sequences and sequence_count >= max_sequences:\n",
    "                    break # 达到最大序列数，停止生成\n",
    "\n",
    "                if pd.isna(temp_df['future_return'].iloc[i]):\n",
    "                    continue\n",
    "\n",
    "                feature_seq_start_idx = i - (self.window_size - 1)\n",
    "                feature_seq_end_idx = i + 1\n",
    "\n",
    "                feature_values_for_seq = temp_df[feature_column_names].iloc[feature_seq_start_idx:feature_seq_end_idx].values\n",
    "\n",
    "                if feature_values_for_seq.shape[0] != self.window_size:\n",
    "                    continue\n",
    "\n",
    "                X.append(feature_values_for_seq.astype(np.float32)) # 立即转换为float32\n",
    "                y.append(temp_df['future_return'].iloc[i].astype(np.float32)) # 立即转换为float32\n",
    "                dates.append(temp_df['日期'].iloc[i])\n",
    "                stocks.append(stock_code)\n",
    "                sequence_count += 1\n",
    "\n",
    "            if max_sequences and sequence_count >= max_sequences:\n",
    "                break # 如果外层循环也达到限制，则停止\n",
    "\n",
    "        if not X:\n",
    "             return np.array([]).reshape(0, self.window_size, num_expected_features), np.array([]), [], []\n",
    "\n",
    "        # 返回 NumPy 数组，类型已为 float32\n",
    "        return np.array(X), np.array(y), dates, stocks"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-06-05T23:05:37.413215Z",
     "end_time": "2025-06-05T23:05:37.416263Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "#======================== 模型部分 ========================\n",
    "\n",
    "class AttentionLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=128, num_layers=3, dropout=0.3):\n",
    "        super(AttentionLSTM, self).__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0, # 如果只有一层，dropout设为0\n",
    "            bidirectional=True\n",
    "        )\n",
    "\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(hidden_size * 2, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, 1)\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size * 2, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        attention_weights = torch.softmax(self.attention(lstm_out), dim=1)\n",
    "        context = torch.sum(attention_weights * lstm_out, dim=1)\n",
    "        out = self.fc(context)\n",
    "        return out\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-06-05T23:05:38.567169Z",
     "end_time": "2025-06-05T23:05:38.573325Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class StockDataset(Dataset):\n",
    "    def __init__(self, X, y=None):\n",
    "        # 确保X是np.array并且是float32类型\n",
    "        self.X = X.astype(np.float32) if isinstance(X, np.ndarray) else np.array(X, dtype=np.float32)\n",
    "        # 确保y是np.array并且是float32类型\n",
    "        self.y = y.astype(np.float32) if y is not None and isinstance(y, np.ndarray) else (np.array(y, dtype=np.float32) if y is not None else None)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is not None:\n",
    "            return torch.from_numpy(self.X[idx]), torch.tensor(self.y[idx]) # 使用from_numpy避免复制\n",
    "        else:\n",
    "            return torch.from_numpy(self.X[idx])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-06-05T23:05:40.292867Z",
     "end_time": "2025-06-05T23:05:40.298533Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 开始股票预测模型训练 (内存优化版) ===\n",
      "1. 读取训练数据...\n",
      "训练或预测过程发生错误: [Errno 2] No such file or directory: '/kaggle/input/2025bdc/train.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\骆鞠恒\\AppData\\Local\\Temp\\ipykernel_66300\\3324082121.py\", line 289, in main\n",
      "    train_data = pd.read_csv('/kaggle/input/2025bdc/train.csv', encoding='utf-8')\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\programming\\1111ANCONDAZ_END\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 912, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\programming\\1111ANCONDAZ_END\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 577, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\programming\\1111ANCONDAZ_END\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1407, in __init__\n",
      "    self._engine = self._make_engine(f, self.engine)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\programming\\1111ANCONDAZ_END\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1661, in _make_engine\n",
      "    self.handles = get_handle(\n",
      "                   ^^^^^^^^^^^\n",
      "  File \"D:\\programming\\1111ANCONDAZ_END\\Lib\\site-packages\\pandas\\io\\common.py\", line 868, in get_handle\n",
      "    handle = open(handle, ioargs.mode)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/kaggle/input/2025bdc/train.csv'\n"
     ]
    }
   ],
   "source": [
    "# ======================== 训练和预测 ========================\n",
    "\n",
    "class StockPredictor:\n",
    "    def __init__(self, window_size=20, hidden_size=128, num_layers=3, dropout=0.3):\n",
    "        self.window_size = window_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.models = []\n",
    "        self.scalers = []\n",
    "        self.feature_cols = None # 用于存储训练时使用的特征列\n",
    "\n",
    "    def train(self, train_data, num_epochs=50, batch_size=64, n_splits=5, max_sequences=None):\n",
    "        processor = StockDataProcessor(self.window_size)\n",
    "\n",
    "        print(\"计算技术指标特征...\")\n",
    "        features = processor.calculate_all_features(train_data)\n",
    "        features = features.ffill().bfill()\n",
    "        features = features.replace([np.inf, -np.inf], np.nan)\n",
    "        features = features.fillna(0) # 最终填充0\n",
    "\n",
    "        if features.empty:\n",
    "            raise ValueError(\"特征计算结果为空，无法继续训练。\")\n",
    "\n",
    "        # 存储使用的特征列，供预测时使用\n",
    "        self.feature_cols = features.columns.tolist()\n",
    "\n",
    "        print(f\"特征形状: {features.shape}\")\n",
    "        print(f\"特征中缺失值数量: {features.isna().sum().sum()}\")\n",
    "        print(f\"特征中无穷值检查: {np.isinf(features.values).sum()}\")\n",
    "\n",
    "        print(\"准备序列数据...\")\n",
    "        # 传递 max_sequences 参数\n",
    "        X, y, _, _ = processor.prepare_sequences(train_data, features, max_sequences=max_sequences)\n",
    "\n",
    "        # 清理features DataFrame内存\n",
    "        del features\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        if X.size == 0 or len(X) == 0:\n",
    "            raise ValueError(\"没有足够的数据用于训练，序列为空。\")\n",
    "\n",
    "        # 确保X中没有NaN或Inf (在prepare_sequences中已转换为float32并尝试处理，这里是最终检查)\n",
    "        if np.isnan(X).any() or np.isinf(X).any():\n",
    "            print(\"警告: 序列X中存在NaN或Inf，进行最终清理...\")\n",
    "            X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "        print(f\"序列数量: {len(X)}, 每个序列长度: {X.shape[1]}, 特征数量: {X.shape[-1]}\")\n",
    "\n",
    "        # 使用 TimeSeriesSplit 进行交叉验证\n",
    "        tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(tscv.split(X)):\n",
    "            print(f\"\\n训练第 {fold + 1}/{n_splits} 个模型...\")\n",
    "\n",
    "            X_train, X_val = X[train_idx], X[val_idx]\n",
    "            y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "            # 内存优化：在每个折叠内仅保留当前折叠所需的数据\n",
    "            # 由于 X, y 已经是 NumPy 数组，直接切片并不会复制大数据\n",
    "\n",
    "            # 初始化并拟合 RobustScaler\n",
    "            scaler = RobustScaler()\n",
    "            # Reshape X_train to 2D for scaler: (num_samples * sequence_length, num_features)\n",
    "            X_train_2d = X_train.reshape(-1, X_train.shape[-1])\n",
    "            X_train_scaled_2d = scaler.fit_transform(X_train_2d)\n",
    "            X_train_scaled = X_train_scaled_2d.reshape(X_train.shape)\n",
    "\n",
    "            # Transform X_val\n",
    "            X_val_2d = X_val.reshape(-1, X_val.shape[-1])\n",
    "            X_val_scaled_2d = scaler.transform(X_val_2d)\n",
    "            X_val_scaled = X_val_scaled_2d.reshape(X_val.shape)\n",
    "\n",
    "            train_dataset = StockDataset(X_train_scaled, y_train)\n",
    "            val_dataset = StockDataset(X_val_scaled, y_val)\n",
    "\n",
    "            # 释放当前折叠中不需要的原始数据副本\n",
    "            del X_train, X_val, y_train, y_val, X_train_scaled_2d, X_val_2d, X_val_scaled_2d\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            # DataLoader 中设置 num_workers=0 以避免多进程内存复制问题\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "            model = AttentionLSTM(\n",
    "                input_size=X.shape[-1], # num_features\n",
    "                hidden_size=self.hidden_size,\n",
    "                num_layers=self.num_layers,\n",
    "                dropout=self.dropout\n",
    "            ).to(self.device)\n",
    "\n",
    "            criterion = nn.MSELoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "            scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, factor=0.5, verbose=True)\n",
    "\n",
    "            best_val_loss = float('inf')\n",
    "            patience_counter = 0\n",
    "            best_model_state = None\n",
    "\n",
    "            for epoch in range(num_epochs):\n",
    "                model.train()\n",
    "                train_loss = 0\n",
    "                for batch_X, batch_y in train_loader:\n",
    "                    batch_X, batch_y = batch_X.to(self.device), batch_y.to(self.device).squeeze() # Squeeze target for MSELoss\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model(batch_X).squeeze(-1) # Squeeze model output\n",
    "                    loss = criterion(outputs, batch_y)\n",
    "                    loss.backward()\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                    optimizer.step()\n",
    "                    train_loss += loss.item()\n",
    "\n",
    "                # 定期清理GPU内存\n",
    "                torch.cuda.empty_cache()\n",
    "                gc.collect()\n",
    "\n",
    "                model.eval()\n",
    "                val_loss = 0\n",
    "                with torch.no_grad():\n",
    "                    for batch_X, batch_y in val_loader:\n",
    "                        batch_X, batch_y = batch_X.to(self.device), batch_y.to(self.device).squeeze()\n",
    "                        outputs = model(batch_X).squeeze(-1)\n",
    "                        val_loss += criterion(outputs, batch_y).item()\n",
    "\n",
    "                avg_train_loss = train_loss / len(train_loader)\n",
    "                avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "                scheduler.step(avg_val_loss)\n",
    "\n",
    "                if avg_val_loss < best_val_loss:\n",
    "                    best_val_loss = avg_val_loss\n",
    "                    patience_counter = 0\n",
    "                    best_model_state = model.state_dict()\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "\n",
    "                if epoch % 5 == 0 or epoch == num_epochs - 1: # 每5个epoch打印一次\n",
    "                    print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {avg_train_loss:.6f}, Val Loss: {avg_val_loss:.6f}, LR: {optimizer.param_groups[0]['lr']:.7f}\")\n",
    "\n",
    "                if patience_counter >= 10: # 早停耐心值\n",
    "                    print(f\"早停 at epoch {epoch + 1}\")\n",
    "                    break\n",
    "\n",
    "                # 每个epoch结束后再次清理GPU内存\n",
    "                torch.cuda.empty_cache()\n",
    "                gc.collect()\n",
    "\n",
    "            if best_model_state is not None:\n",
    "                model.load_state_dict(best_model_state)\n",
    "                self.models.append(model)\n",
    "                self.scalers.append(scaler)\n",
    "            else:\n",
    "                print(f\"警告: 第 {fold + 1} 折未能成功训练模型。\")\n",
    "\n",
    "            # 清理当前折叠的模型和加载器\n",
    "            del train_loader, val_loader, train_dataset, val_dataset, model\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        # 训练结束后，清理大块序列数据\n",
    "        del X, y\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "    def predict(self, test_data):\n",
    "        if not self.models or not self.scalers or self.feature_cols is None:\n",
    "            print(\"错误: 模型或缩放器未训练或特征列未设置。\")\n",
    "            return pd.DataFrame({'涨幅最大股票代码': [''] * 10, '涨幅最小股票代码': [''] * 10})\n",
    "\n",
    "        processor = StockDataProcessor(self.window_size)\n",
    "\n",
    "        print(\"为测试数据计算特征...\")\n",
    "        features = processor.calculate_all_features(test_data)\n",
    "        features = features.ffill().bfill()\n",
    "        features = features.replace([np.inf, -np.inf], np.nan)\n",
    "        features = features.fillna(0) # 最终填充0\n",
    "\n",
    "        if features.empty:\n",
    "            print(\"错误: 测试数据的特征计算结果为空。\")\n",
    "            return pd.DataFrame({'涨幅最大股票代码': [''] * 10, '涨幅最小股票代码': [''] * 10})\n",
    "\n",
    "        # 确保测试数据使用的特征列与训练时一致\n",
    "        # 如果 test_data 缺少训练时的某些特征，需要填充或报错\n",
    "        missing_features = [col for col in self.feature_cols if col not in features.columns]\n",
    "        if missing_features:\n",
    "            print(f\"警告: 测试数据缺少训练时使用的特征: {missing_features}。将填充0。\")\n",
    "            for col in missing_features:\n",
    "                features[col] = 0.0\n",
    "        # 确保特征顺序一致\n",
    "        features = features[self.feature_cols]\n",
    "\n",
    "        last_prediction_input_date = test_data['日期'].max()\n",
    "        print(f\"将基于日期 {last_prediction_input_date} 的数据进行预测。\")\n",
    "\n",
    "        all_stock_codes = test_data['股票代码'].unique()\n",
    "\n",
    "        X_predict_sequences = []\n",
    "        predict_stock_order = []\n",
    "\n",
    "        for stock_code in all_stock_codes:\n",
    "            current_stock_data_slice = test_data[test_data['股票代码'] == stock_code]\n",
    "            # 从全局 features 中获取当前股票的特征\n",
    "            current_stock_features_slice = features.loc[current_stock_data_slice.index]\n",
    "\n",
    "            temp_df = current_stock_data_slice[['日期']].join(current_stock_features_slice)\n",
    "            temp_df = temp_df.sort_values('日期').reset_index(drop=True)\n",
    "\n",
    "            if temp_df.empty or temp_df['日期'].iloc[-1] != last_prediction_input_date:\n",
    "                continue\n",
    "            if len(temp_df) < self.window_size:\n",
    "                continue\n",
    "\n",
    "            last_sequence = temp_df[self.feature_cols].iloc[-self.window_size:].values # 使用保存的特征列顺序\n",
    "\n",
    "            if last_sequence.shape[0] != self.window_size:\n",
    "                continue\n",
    "\n",
    "            if np.isnan(last_sequence).any() or np.isinf(last_sequence).any():\n",
    "                last_sequence = np.nan_to_num(last_sequence, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "            X_predict_sequences.append(last_sequence.astype(np.float32))\n",
    "            predict_stock_order.append(stock_code)\n",
    "\n",
    "        if not X_predict_sequences:\n",
    "            print(\"没有为任何股票准备好有效的预测序列。\")\n",
    "            return pd.DataFrame({'涨幅最大股票代码': [''] * 10, '涨幅最小股票代码': [''] * 10})\n",
    "\n",
    "        X_predict_array = np.array(X_predict_sequences) # (num_stocks_to_predict, window_size, num_features)\n",
    "\n",
    "        ensemble_predictions = np.zeros(len(predict_stock_order))\n",
    "\n",
    "        for model_idx, (model, scaler) in enumerate(zip(self.models, self.scalers)):\n",
    "            X_pred_2d = X_predict_array.reshape(-1, X_predict_array.shape[-1])\n",
    "            X_pred_scaled_2d = scaler.transform(X_pred_2d) # 使用对应的 scaler\n",
    "            X_pred_scaled = X_pred_scaled_2d.reshape(X_predict_array.shape)\n",
    "\n",
    "            X_tensor = torch.from_numpy(X_pred_scaled).to(self.device) # 使用 from_numpy\n",
    "\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                current_model_preds = model(X_tensor).cpu().numpy().squeeze(-1)\n",
    "            ensemble_predictions += current_model_preds\n",
    "\n",
    "            # 预测后立即清理GPU内存\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "        if self.models:\n",
    "            ensemble_predictions /= len(self.models)\n",
    "\n",
    "        predictions_map = {stock_code: pred for stock_code, pred in zip(predict_stock_order, ensemble_predictions)}\n",
    "\n",
    "        valid_predictions = {k: v for k, v in predictions_map.items() if pd.notna(v) and np.isfinite(v)}\n",
    "        sorted_stocks = sorted(valid_predictions.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "        top_10 = [stock[0] for stock in sorted_stocks[:10]]\n",
    "        bottom_10_sorted = sorted_stocks[-10:] # 取最后10个\n",
    "        bottom_10 = [stock[0] for stock in bottom_10_sorted]\n",
    "\n",
    "        while len(top_10) < 10:\n",
    "            top_10.append('')\n",
    "        while len(bottom_10) < 10:\n",
    "            bottom_10.append('')\n",
    "\n",
    "        result_df = pd.DataFrame({\n",
    "            '涨幅最大股票代码': top_10,\n",
    "            '涨幅最小股票代码': bottom_10\n",
    "        })\n",
    "\n",
    "        return result_df\n",
    "\n",
    "\n",
    "# ======================== 主程序 ========================\n",
    "def main():\n",
    "    print(\"=== 开始股票预测模型训练 (内存优化版) ===\")\n",
    "\n",
    "    try:\n",
    "        print(\"1. 读取训练数据...\")\n",
    "        # 即使数据量大，也尝试一次性读取，因为后续会通过 max_sequences 和分块处理\n",
    "        # 比赛数据量对于 train.csv (2015-2025) 来说，如果直接读取，需要足够的内存\n",
    "        # 如果还是爆内存，考虑像参考代码一样，先保存为 feather 或 parquet 格式，然后再分块读取。\n",
    "        # 或者在 main 函数中也实现分块读取（但不计算特征）。\n",
    "        # 这里为了简化，假设 train.csv 能够被一次性加载。\n",
    "        train_data = pd.read_csv('/kaggle/input/2025bdc/train.csv', encoding='utf-8')\n",
    "        test_data = pd.read_csv('/kaggle/input/2025bdc/test.csv', encoding='utf-8')\n",
    "\n",
    "        # 检查文件是否存在，防止路径错误\n",
    "        if train_data.empty or test_data.empty:\n",
    "            raise FileNotFoundError(\"训练或测试数据文件可能为空或路径错误。\")\n",
    "\n",
    "        print(f\"原始训练数据形状: {train_data.shape}\")\n",
    "        print(f\"原始测试数据形状: {test_data.shape}\")\n",
    "\n",
    "        # 列名检查和映射\n",
    "        required_columns = ['日期', '股票代码', '开盘', '最高', '最低', '收盘', '成交量']\n",
    "        column_mapping = {\n",
    "            '日期': ['date', 'Date', 'DATE', 'trade_date'], '股票代码': ['code', 'Code', 'CODE', 'stock_code', 'symbol', 'ts_code'],\n",
    "            '开盘': ['open', 'Open', 'OPEN'], '最高': ['high', 'High', 'HIGH'],\n",
    "            '最低': ['low', 'Low', 'LOW'], '收盘': ['close', 'Close', 'CLOSE'],\n",
    "            '成交量': ['volume', 'Volume', 'VOLUME', 'vol']\n",
    "        }\n",
    "        for df in [train_data, test_data]:\n",
    "            missing_cols_in_df = [col for col in required_columns if col not in df.columns]\n",
    "            if missing_cols_in_df:\n",
    "                for chinese_col, possible_names in column_mapping.items():\n",
    "                    if chinese_col in missing_cols_in_df:\n",
    "                        for eng_col in possible_names:\n",
    "                            if eng_col in df.columns:\n",
    "                                df.rename(columns={eng_col: chinese_col}, inplace=True)\n",
    "                                break\n",
    "            final_missing = [col for col in required_columns if col not in df.columns]\n",
    "            if final_missing:\n",
    "                raise ValueError(f\"数据帧中仍缺少必要的列: {final_missing}，即使在尝试映射后。\")\n",
    "\n",
    "        # 数据预处理\n",
    "        for df in [train_data, test_data]:\n",
    "            df['日期'] = pd.to_datetime(df['日期'])\n",
    "            numeric_cols_to_convert = ['开盘', '最高', '最低', '收盘', '成交量', '成交额', '换手率', '振幅', '涨跌额', '涨跌幅']\n",
    "            for col in numeric_cols_to_convert:\n",
    "                if col in df.columns:\n",
    "                    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "            df.dropna(subset=['开盘', '最高', '最低', '收盘', '成交量'], inplace=True) # 只对核心列进行dropna\n",
    "            if '股票代码' in df.columns:\n",
    "                 df['股票代码'] = df['股票代码'].astype(str)\n",
    "\n",
    "        print(f\"清理后训练数据形状: {train_data.shape}\")\n",
    "        print(f\"清理后测试数据形状: {test_data.shape}\")\n",
    "\n",
    "        if train_data.empty or test_data.empty:\n",
    "            print(\"错误：预处理后数据为空！无法继续。\")\n",
    "            return\n",
    "\n",
    "        print(\"2. 初始化预测器并训练模型...\")\n",
    "        predictor = StockPredictor(\n",
    "            window_size=20,\n",
    "            hidden_size=128,\n",
    "            num_layers=3,\n",
    "            dropout=0.3\n",
    "        )\n",
    "\n",
    "        # 训练模型，并设定 max_sequences 限制训练数据量\n",
    "        # 这个参数非常关键，用于控制传入LSTM的序列数量，防止OOM\n",
    "        # 根据你的显存大小调整这个值\n",
    "        # 100000 序列可能在 8GB 或 16GB GPU 上是可行的，如果仍OOM，请降低\n",
    "        predictor.train(\n",
    "            train_data,\n",
    "            num_epochs=50,\n",
    "            batch_size=64,\n",
    "            n_splits=5,\n",
    "            max_sequences=300000 # 限制训练序列总数，防止内存溢出。请根据你的显存大小调整。\n",
    "        )\n",
    "\n",
    "        print(\"3. 生成预测结果...\")\n",
    "        result = predictor.predict(test_data)\n",
    "\n",
    "        print(\"4. 保存结果...\")\n",
    "        result.to_csv('result.csv', index=False, encoding='utf-8')\n",
    "        print(\"预测结果已保存到 result.csv\")\n",
    "        print(\"预测结果样本:\")\n",
    "        print(result.head())\n",
    "\n",
    "        # 清理最终内存\n",
    "        del train_data, test_data, result, predictor\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        print(\"\\n=== 内存优化训练完成 ===\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"训练或预测过程发生错误: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc() # 打印详细错误栈\n",
    "\n",
    "        # 确保在出错时也尝试释放GPU内存\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-06-05T23:05:41.443118Z",
     "end_time": "2025-06-05T23:05:41.534088Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
